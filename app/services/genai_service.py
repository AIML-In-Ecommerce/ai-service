import replicate
from langchain.prompts import ChatPromptTemplate
from openai import OpenAI
from dotenv import load_dotenv
from app.prompts.prompt import review_synthesis_prompt_tmpl_str, generate_product_description_prompt_tmpl_str, data_visualization_tool_prompt_tmpl_str
import json
import os
load_dotenv()

OPENAI_KEY = os.getenv('OPENAI_API_KEY')

# REVIEW_SYSTHESIS_SYSTEM_MSG = """B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch ƒë√°nh gi√°, b·∫°n s·∫Ω ƒë∆∞·ª£c cung c·∫•p m·ªôt danh s√°ch c√°c ƒë√°nh gi√° c·ªßa m·ªôt s·∫£n ph·∫©m, h√£y ph√¢n t√≠ch c√°c ƒë√°nh gi√° ƒë√≥. H√£y ƒë·∫£m b·∫£o k·∫øt qu·∫£ tr·∫£ v·ªÅ lu√¥n lu√¥n l√† m·ªôt json v·ªõi c·∫•u tr√∫c {"positiveCount" : ƒë√¢y l√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° t√≠ch c·ª±c , "negativeCount": ƒë√¢y l√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° ti√™u c·ª±c, "trashCount" : ƒë√¢y l√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° kh√¥ng th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c l√† ti√™u c·ª±c hay t√≠ch c·ª±c, "positiveSumary" : "ƒê√¢y l√† m·ªôt ƒëo·∫°n t√≥m t·∫Øt m√¥ t·∫£ ng·∫Øn v·ªÅ c√°c ƒë√°nh gi√° t√≠ch c·ª±c, ƒë·ªô d√†i ƒëo·∫°n t√≥m t·∫Øt kho·∫£ng 50 t·ª´. V√≠ d·ª•: H·∫ßu h·∫øt ng∆∞·ªùi mua ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m, bao g·ªìm v·∫£i ƒë·∫πp, ch·∫•t jean d√†y d·∫∑n, co gi√£n t·ªët v√† form chu·∫©n. M·ªôt s·ªë kh√°ch h√†ng nh·∫≠n x√©t s·∫£n ph·∫©m ƒë√°ng mua, ƒë·∫πp, sang tr·ªçng v√† b·ªÅn ch·∫Øc. ƒêa s·ªë kh√°ch h√†ng h√†i l√≤ng v·ªõi d·ªãch v·ª• giao h√†ng nhanh, ƒë√∫ng h·∫πn v√† ƒë√≥ng g√≥i c·∫©n th·∫≠n. M·ªôt s·ªë kh√°ch h√†ng ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ s·ª± nhi·ªát t√¨nh v√† tr√°ch nhi·ªám c·ªßa shop.", "negativeSumary" : "ƒê√¢y l√† m·ªôt ƒëo·∫°n t√≥m t·∫Øt m√¥ t·∫£ ng·∫Øn v·ªÅ c√°c ƒë√°nh gi√° ti√™u c·ª±c,ƒë·ªô d√†i ƒëo·∫°n t√≥m t·∫Øt kho·∫£ng 30 t·ª´. V√≠ d·ª•: Tuy nhi√™n, c√≥ m·ªôt s·ªë nh·∫≠n x√©t ti√™u c·ª±c v·ªÅ khuy n√∫t b·ªã l·ªèng v√† m√†u kh√¥ng th√≠ch, c√≥ m·ªôt nh·∫≠n x√©t ti√™u c·ª±c v·ªÅ vi·ªác nh·∫ßm h√†ng."}.
# """

# GENERATE_DESCRIPTION_SYSTEM_MSG = """B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o tr√™n n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ ƒëang h·ªó tr·ª£ ng∆∞·ªùi d√πng vi·∫øt m√¥ t·∫£ cho s·∫£n ph·∫©m c·ªßa h·ªç. B·∫°n s·∫Ω ƒë∆∞·ª£c cung c·∫•p m·ªôt ƒëo·∫°n m√¥ t·∫£ s·∫£n ph·∫©m m·∫´u v√† m·ªôt ƒëo·∫°n m√¥ t·∫£ s∆° l∆∞·ª£c v·ªÅ s·∫£n ph·∫©m c·ªßa kh√°ch h√†ng cung c·∫•p ·ªü d·∫°ng html, bao g·ªìm c√°c th·∫ª ch·ª©a th√¥ng tin s∆° b·ªô c√≥ th·ªÉ c√≥ th·∫ª h√¨nh ·∫£nh ho·∫∑c c√°c th·∫ª kh√°c. H√£y vi·∫øt l·∫°i m√¥ t·∫£ s·∫£n ph·∫©m d·ª±a tr√™n th√¥ng tin m√† kh√°ch h√†ng cung c·∫•p v√† tu√¢n theo format c·ªßa m√¥ t·∫£ m·∫´u v·ªõi t·ª´ ng·ªØ ph√π h·ª£p. B·∫°n c√≥ th·ªÉ vi·∫øt th√™m m√¥ t·∫£ theo c√°c th√¥ng tin m√† b·∫°n bi·∫øt v·ªÅ ch·∫•t li·ªáu, thi·∫øt k·∫ø, k√≠ch c·ª° v·ªõi t·ª´ ng·ªØ c√†ng sinh ƒë·ªông c√†ng t·ªët. Ch√∫ √Ω m√¥ t·∫£ m·∫´u ch·ªâ l√† thi·∫øt k·∫ø m·∫´u, kh√¥ng nh·∫•t thi·∫øt ph·∫£i ƒë·∫ßy ƒë·ªß gi·ªëng nh∆∞ m·∫´u, b·∫°n ph·∫£i d·ª±a tr√™n m√¥ t·∫£ s∆° l∆∞·ª£c do ng∆∞·ªùi d√πng cung c·∫•p v√† vi·∫øt l·∫°i m·ªôt c√°ch n·ªïi b·∫≠t
# ƒêo·∫°n m√¥ t·∫£ s·∫£n ph·∫©m m·∫´u ph√≠a d∆∞·ªõi:
# ---------------------------------------
# <p class="QN2lPu"><strong>&Aacute;o s∆° mi nam ng·∫Øn tay c·ªï th∆∞·ªùng tho&aacute;ng m&aacute;t kh&aacute;ng khu·∫©n, form ƒë·∫πp d·ªÖ ph·ªëi ƒë·ªì</strong></p> <!-- This is name of product-->
# <p class="QN2lPu">‚è© Th&ocirc;ng tin s·∫£n ph·∫©m:</p> <!-- This is section title-->
# <p class="QN2lPu">üëâ Ch·∫•t li·ªáu: ch·∫•t ƒë≈©i th·∫•m h&uacute;t t·ªët, tho&aacute;ng m&aacute;t</p> <!-- This is content of this section-->
# <p class="QN2lPu">&nbsp;</p>
# <p class="QN2lPu"><img style="display: block; margin-left: auto; margin-right: auto;" src="https://down-vn.img.susercontent.com/file/vn-11134207-7qukw-ley33b4kzpmyac" alt="" width="573" height="573"></p> <!-- This is image tag if user have provided image link-->
# <p class="QN2lPu"><video style="width: 612px; height: 306px; display: table; margin-left: auto; margin-right: auto;" controls="controls" width="612" height="306"> <source src="https://cvf.shopee.vn/file/api/v4/11110105/mms/vn-11110105-6ke15-lu7a25d0b1n547.16000081713323497.mp4" type="video/mp4"></video></p> <!-- This is video tag if user have provided video link-->
# <p class="QN2lPu"><strong>TH&Ocirc;NG TIN TH∆Ø∆†NG HI·ªÜU</strong></p>
# <p class="QN2lPu"><strong>LADOS </strong>l&agrave; Nh&agrave; ph&acirc;n ph·ªëi chuy&ecirc;n s·ªâ &amp; l·∫ª c&aacute;c m·∫∑t h&agrave;ng th·ªùi trang ch·∫•t l∆∞·ª£ng v&agrave; gi&aacute; c·∫£ ph·∫£i chƒÉng v·ªõi th∆∞∆°ng hi·ªáu LADOS. Ch&uacute;ng t&ocirc;i h&acirc;n h·∫°nh v&agrave; lu&ocirc;n c·ªë g·∫Øng ƒë·ªÉ mang ƒë·∫øn cho qu&yacute; kh&aacute;ch nh·ªØng s·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng v·ªõi gi&aacute; c·∫£ t·ªët nh·∫•t v&agrave; d·ªãch v·ª• uy t&iacute;n. T·∫•t c·∫£ c&aacute;c s·∫£n ph·∫©m c·ªßa shop ƒë·ªÅu ƒë∆∞·ª£c ch&uacute;ng t&ocirc;i tuy·ªÉn ch·ªçn m·ªôt c&aacute;ch k·ªπ l∆∞·ª°ng sao cho ph&ugrave; h·ª£p v·ªõi phong c&aacute;ch Ch&acirc;u &Aacute; v&agrave; b·∫Øt nh·ªãp c&ugrave;ng xu h∆∞·ªõng tr·∫ª. ƒê·∫øn v·ªõi ch&uacute;ng t&ocirc;i kh&aacute;ch h&agrave;ng c&oacute; th·ªÉ y&ecirc;n t&acirc;m mua h&agrave;ng v·ªõi nhi·ªÅu m·∫´u m&atilde; ƒë∆∞·ª£c c·∫≠p nh·∫≠t th∆∞·ªùng xuy&ecirc;n v&agrave; nhi·ªÅu khuy·∫øn m·∫°i h·∫•p d·∫´n.</p>
# <p class="QN2lPu">üì£ CH&Iacute;NH S&Aacute;CH MUA H&Agrave;NG</p> <!-- This is additional section title (if any)-->
# <p class="QN2lPu">üëâ Cam k·∫øt ch·∫•t l∆∞·ª£ng v&agrave; m·∫´u m&atilde; s·∫£n ph·∫©m gi·ªëng v·ªõi h&igrave;nh ·∫£nh.</p>  <!-- This is content of this section-->
# <p class="QN2lPu">üëâ Ho&agrave;n ti·ªÅn n·∫øu s·∫£n ph·∫©m kh&ocirc;ng gi·ªëng v·ªõi m&ocirc; t·∫£.</p>
# <p class="QN2lPu">üëâ ƒê·ªîI TR·∫¢ TRONG 7 NG&Agrave;Y N·∫æU KH&Ocirc;NG ƒê&Uacute;NG MI&Ecirc;U T·∫¢</p>
# <p class="QN2lPu">&nbsp;</p>
# ----------------------------------------
# ƒêo·∫°n m√¥ t·∫£ s∆° l∆∞·ª£c do ng∆∞·ªùi d√πng cung c·∫•p ph√≠a d∆∞·ªõi:
# ----------------------------------------
# {prompt}
# ----------------------------------------
# H√£y ƒë·∫£m b·∫£o r·∫±ng k·∫øt qu·∫£ tr·∫£ v·ªÅ lu√¥n lu√¥n ch·ªâ l√† ƒëo·∫°n m√£ html v√† ng√¥n ng·ªØ c·ªßa ph·∫ßn m√¥ t·∫£ d·ª±a theo ph·∫ßn m√¥ t·∫£ t√¥i cung c·∫•p (∆∞u ti√™n ti·∫øng vi·ªát) v√† ph·∫ßn m√¥ t·∫£ kh√¥ng v∆∞·ª£t qu√° 500 t·ª´. 
# """

def getReviewSynthesis(query):
    client = OpenAI(
        api_key = OPENAI_KEY,
    )
    print("Query", query)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": review_synthesis_prompt_tmpl_str},
            {"role": "user", "content": query}
        ],
    )
    message = response.choices[0].message.content
    return message

def index(query):
    client = OpenAI(
        api_key = OPENAI_KEY,
    )
    print("Query", query)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "user", "content": query}
        ],
    )
    message = response.choices[0].message.content
    return message

def generateProductDesciption(shortDescription):
    client = OpenAI(
        api_key = OPENAI_KEY,
    )
    print("Query", shortDescription)

    SYSTEM_MSG = generate_product_description_prompt_tmpl_str.format(prompt=shortDescription)

    print(SYSTEM_MSG)

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": SYSTEM_MSG},
            {"role": "user", "content": shortDescription}
        ],
    )
    message = response.choices[0].message.content
    return message

def generateChart(data: str):
    client = OpenAI(
        api_key = OPENAI_KEY,
    )
    print("Data", data)

    SYSTEM_MSG = data_visualization_tool_prompt_tmpl_str.format(user_prompt=data)

    print(SYSTEM_MSG)

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": SYSTEM_MSG},
            {"role": "user", "content": data}
        ],
    )
    message = response.choices[0].message.content
    return message



def generateProductImage(prompt: str, context: str, garmentImage: str):
    comfyuiApiWorkflow = {
      "3": {
        "inputs": {
          "seed": 780862346192377,
          "steps": 35,
          "cfg": 8,
          "sampler_name": "dpmpp_2m",
          "scheduler": "karras",
          "denoise": 1,
          "model": [
            "4",
            0
          ],
          "positive": [
            "6",
            0
          ],
          "negative": [
            "7",
            0
          ],
          "latent_image": [
            "5",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "4": {
        "inputs": {
          "ckpt_name": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
          "title": "Load Checkpoint"
        }
      },
      "5": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "6": {
        "inputs": {
          "text": prompt,
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "7": {
        "inputs": {
          "text": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgl, render, blender, digital art, manga, amateur:1.3), (3D, 3D Game, 3D Game Scene, 3D Character:1.1), acne",
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "3",
            0
          ],
          "vae": [
            "4",
            2
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "10": {
        "inputs": {
          "image": "$10-0",
          "images": [
            "8",
            0
          ]
        },
        "class_type": "PreviewBridge",
        "_meta": {
          "title": "Preview Bridge (Image)"
        }
      },
      "11": {
        "inputs": {
          "channel": "red",
          "image": [
            "25",
            0
          ]
        },
        "class_type": "ImageToMask",
        "_meta": {
          "title": "Convert Image to Mask"
        }
      },
      "25": {
        "inputs": {
          "resolution": 1024,
          "image": [
            "10",
            0
          ]
        },
        "class_type": "OneFormer-COCO-SemSegPreprocessor",
        "_meta": {
          "title": "OneFormer COCO Segmentor"
        }
      },
      "26": {
        "inputs": {
          "image": "$26-0",
          "images": [
            "25",
            0
          ]
        },
        "class_type": "PreviewBridge",
        "_meta": {
          "title": "Preview Bridge (Image)"
        }
      },
      "27": {
        "inputs": {
          "image": "$27-0",
          "images": [
            "10",
            0
          ]
        },
        "class_type": "PreviewBridge",
        "_meta": {
          "title": "Preview Bridge (Image)"
        }
      },
      "28": {
        "inputs": {
          "weight": 0.5,
          "weight_faceidv2": 1.5,
          "weight_type": "linear",
          "combine_embeds": "concat",
          "start_at": 0,
          "end_at": 1,
          "embeds_scaling": "V only",
          "model": [
            "4",
            0
          ],
          "ipadapter": [
            "29",
            0
          ],
          "image": [
            "27",
            0
          ],
          "attn_mask": [
            "11",
            0
          ],
          "clip_vision": [
            "30",
            0
          ],
          "insightface": [
            "31",
            0
          ]
        },
        "class_type": "IPAdapterFaceID",
        "_meta": {
          "title": "IPAdapter FaceID"
        }
      },
      "29": {
        "inputs": {
          "ipadapter_file": "ip-adapter-faceid-plusv2_sdxl.bin"
        },
        "class_type": "IPAdapterModelLoader",
        "_meta": {
          "title": "IPAdapter Model Loader"
        }
      },
      "30": {
        "inputs": {
          "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
        },
        "class_type": "CLIPVisionLoader",
        "_meta": {
          "title": "Load CLIP Vision"
        }
      },
      "31": {
        "inputs": {
          "provider": "CPU"
        },
        "class_type": "IPAdapterInsightFaceLoader",
        "_meta": {
          "title": "IPAdapter InsightFace Loader"
        }
      },
      "33": {
        "inputs": {
          "ipadapter_file": "ip-adapter-plus-face_sdxl_vit-h.safetensors"
        },
        "class_type": "IPAdapterModelLoader",
        "_meta": {
          "title": "IPAdapter Model Loader"
        }
      },
      "34": {
        "inputs": {
          "weight": 0.3,
          "weight_type": "linear",
          "combine_embeds": "concat",
          "start_at": 0,
          "end_at": 1,
          "embeds_scaling": "V only",
          "model": [
            "28",
            0
          ],
          "ipadapter": [
            "33",
            0
          ],
          "image": [
            "27",
            0
          ],
          "attn_mask": [
            "11",
            0
          ],
          "clip_vision": [
            "30",
            0
          ]
        },
        "class_type": "IPAdapterAdvanced",
        "_meta": {
          "title": "IPAdapter Advanced"
        }
      },
      "35": {
        "inputs": {
          "text": context,
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "36": {
        "inputs": {
          "text": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgl, render, blender, digital art, manga, amateur:1.3), (3D, 3D Game, 3D Game Scene, 3D Character:1.1), acne",
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "37": {
        "inputs": {
          "seed": 290334798307561,
          "steps": 35,
          "cfg": 8,
          "sampler_name": "dpmpp_2m",
          "scheduler": "karras",
          "denoise": 1,
          "model": [
            "54",
            0
          ],
          "positive": [
            "35",
            0
          ],
          "negative": [
            "36",
            0
          ],
          "latent_image": [
            "38",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "38": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "39": {
        "inputs": {
          "samples": [
            "37",
            0
          ],
          "vae": [
            "4",
            2
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "41": {
        "inputs": {
          "image": garmentImage, 
          "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Load Image"
        }
      },
      "42": {
        "inputs": {
          "resolution": 1024,
          "image": [
            "41",
            0
          ]
        },
        "class_type": "UniFormer-SemSegPreprocessor",
        "_meta": {
          "title": "UniFormer Segmentor"
        }
      },
      "43": {
        "inputs": {
          "channel": "red",
          "image": [
            "42",
            0
          ]
        },
        "class_type": "ImageToMask",
        "_meta": {
          "title": "Convert Image to Mask"
        }
      },
      "44": {
        "inputs": {
          "ipadapter_file": "ip-adapter-plus_sdxl_vit-h.safetensors"
        },
        "class_type": "IPAdapterModelLoader",
        "_meta": {
          "title": "IPAdapter Model Loader"
        }
      },
      "48": {
        "inputs": {
          "images": [
            "42",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "Preview Image"
        }
      },
      "54": {
        "inputs": {
          "weight": 1,
          "weight_type": "linear",
          "combine_embeds": "concat",
          "start_at": 0,
          "end_at": 1,
          "embeds_scaling": "V only",
          "model": [
            "34",
            0
          ],
          "ipadapter": [
            "44",
            0
          ],
          "image": [
            "41",
            0
          ],
          "attn_mask": [
            "43",
            0
          ],
          "clip_vision": [
            "30",
            0
          ]
        },
        "class_type": "IPAdapterAdvanced",
        "_meta": {
          "title": "IPAdapter Advanced"
        }
      },
      "55": {
        "inputs": {
          "filename_prefix": "ComfyUI",
          "images": [
            "39",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      }
    }

    workflowJson =  json.dumps(comfyuiApiWorkflow, indent=2)
    output = replicate.run(
        "fofr/any-comfyui-workflow:6c42f2d9c7c0fcc873656b0156b554cde147118960a02c10c14e44312f9c8d7f",
        input={
            "output_format": "webp",
            "workflow_json": workflowJson,
            "output_quality": 80,
            "randomise_seeds": True,
            "return_temp_files": False
        }
    )
    return {
        "prompt": prompt,
        "context": context,
        "garmentImage": garmentImage,
        "genaiProductImage": output,
    }

def generateTryOnImage(modelImage:str, garmentImage:str):
    output = replicate.run(
        "viktorfa/oot_diffusion:9f8fa4956970dde99689af7488157a30aa152e23953526a605df1d77598343d7",
        input={
            "seed": 0,
            "steps": 20,
            "model_image": modelImage,
            "garment_image": garmentImage,
            "guidance_scale": 2
        }
    )

    return {
        "modelImage": modelImage,
        "garmentImage": garmentImage,
        "tryOnImage": output
    }